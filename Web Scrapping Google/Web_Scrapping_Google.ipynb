{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from googlesearch import search\n",
        "from urllib.parse import urlparse\n",
        "import time\n",
        "import logging\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Deshabilita las advertencias de certificados no verificados\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "# Configuración del logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Lista de User-Agents para rotar\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/89.0',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.59 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'\n",
        "]\n",
        "\n",
        "def scraping_data(query, query_type):\n",
        "    \"\"\"\n",
        "    Función unificada para realizar web scraping, ya sea por URL o por nombre.\n",
        "    \"\"\"\n",
        "    # Selecciona un User-Agent al azar para cada solicitud\n",
        "    headers = {'User-Agent': random.choice(user_agents)}\n",
        "    url_final = None\n",
        "\n",
        "    if query_type == \"url\":\n",
        "        url_final = query\n",
        "    elif query_type == \"nombre\":\n",
        "        try:\n",
        "            resultados_busqueda = list(search(query, stop=1, pause=random.uniform(2, 4)))\n",
        "            if not resultados_busqueda:\n",
        "                logging.warning(f\"No se encontró URL para el nombre: {query}\")\n",
        "                return None\n",
        "            url_final = resultados_busqueda[0]\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error en la búsqueda de Google para '{query}': {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        logging.error(\"Tipo de consulta no válido. Use 'url' o 'nombre'.\")\n",
        "        return None\n",
        "\n",
        "    logging.info(f\"URL final a procesar: {url_final}\")\n",
        "\n",
        "    # Obtener el dominio de la URL\n",
        "    dominio = urlparse(url_final).netloc\n",
        "\n",
        "    # Realizar web scraping con manejo de errores y reintentos\n",
        "    response = None\n",
        "    for _ in range(3):\n",
        "        try:\n",
        "            response = requests.get(url_final, headers=headers, timeout=30, verify=False)\n",
        "            response.raise_for_status()\n",
        "            break\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logging.error(f\"Intento fallido para {url_final}: {e}. Reintentando...\")\n",
        "            time.sleep(random.uniform(5, 10))\n",
        "\n",
        "    if not response:\n",
        "        logging.error(f\"No se pudo acceder a la URL después de varios intentos: {url_final}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # --- Extracción de información general ---\n",
        "    titulo = soup.title.text.strip() if soup.title else None\n",
        "    descripcion = soup.find('meta', {'name': 'description'})\n",
        "    descripcion = descripcion['content'].strip() if descripcion else None\n",
        "    palabras_clave = soup.find('meta', {'name': 'keywords'})\n",
        "    palabras_clave = palabras_clave['content'].strip() if palabras_clave else None\n",
        "    encabezados = [h.text.strip() for h in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n",
        "    enlaces = [link.get('href') for link in soup.find_all('a', href=True)]\n",
        "    parrafos = [p.text.strip() for p in soup.find_all('p')]\n",
        "    imagenes = [img.get('src') for img in soup.find_all('img', src=True)]\n",
        "    tablas = []\n",
        "    for table in soup.find_all('table'):\n",
        "        table_data = []\n",
        "        for row in table.find_all('tr'):\n",
        "            row_data = [cell.text.strip() for cell in row.find_all(['td', 'th'])]\n",
        "            table_data.append(row_data)\n",
        "        tablas.append(table_data)\n",
        "\n",
        "    # --- Nuevos campos de búsqueda ---\n",
        "    razon_social = None\n",
        "    tax_id = None\n",
        "    brand = None\n",
        "    email = None\n",
        "    telefono = None\n",
        "    direccion = None\n",
        "    productos_servicios = []\n",
        "\n",
        "    # Búsqueda en datos estructurados de Schema.org\n",
        "    for script in soup.find_all('script', type='application/ld+json'):\n",
        "        if script.string:\n",
        "            try:\n",
        "                data = json.loads(script.string)\n",
        "                if isinstance(data, list):\n",
        "                    for item in data:\n",
        "                        if item.get('@type') in ['Organization', 'LocalBusiness']:\n",
        "                            razon_social = item.get('name')\n",
        "                            tax_id = item.get('taxID')\n",
        "                            brand = item.get('brand')\n",
        "                            if item.get('address') and isinstance(item['address'], dict):\n",
        "                                direccion = item['address'].get('streetAddress')\n",
        "                            if item.get('contactPoint') and isinstance(item['contactPoint'], list):\n",
        "                                for cp in item['contactPoint']:\n",
        "                                    if cp.get('contactType') == 'customer service' or cp.get('contactType') == 'general':\n",
        "                                        telefono = cp.get('telephone')\n",
        "                                        email = cp.get('email')\n",
        "                        elif item.get('@type') in ['Product', 'Service']:\n",
        "                            productos_servicios.append(item.get('name'))\n",
        "                elif data.get('@type') in ['Organization', 'LocalBusiness']:\n",
        "                    razon_social = data.get('name')\n",
        "                    tax_id = data.get('taxID')\n",
        "                    brand = data.get('brand')\n",
        "                    if data.get('address') and isinstance(data['address'], dict):\n",
        "                        direccion = data['address'].get('streetAddress')\n",
        "                    if data.get('contactPoint') and isinstance(data['contactPoint'], list):\n",
        "                        for cp in data['contactPoint']:\n",
        "                            if cp.get('contactType') == 'customer service' or cp.get('contactType') == 'general':\n",
        "                                telefono = cp.get('telephone')\n",
        "                                email = cp.get('email')\n",
        "                elif data.get('@type') in ['Product', 'Service']:\n",
        "                    productos_servicios.append(data.get('name'))\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "    # Si no se encuentra razón social en Schema.org, buscar en el h1\n",
        "    if not razon_social:\n",
        "        razon_social_element = soup.find('h1')\n",
        "        razon_social = razon_social_element.text.strip() if razon_social_element else None\n",
        "\n",
        "    # Si no se encuentra email o teléfono, buscar por patrones\n",
        "    if not email:\n",
        "        email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.[\\w\\.]+', str(soup))\n",
        "        email = email_match.group(0) if email_match else None\n",
        "\n",
        "    if not telefono:\n",
        "        telefono_match = re.search(r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', str(soup))\n",
        "        telefono = telefono_match.group(0) if telefono_match else None\n",
        "\n",
        "    return {\n",
        "        'nombre_buscado': query if query_type == 'nombre' else None,\n",
        "        'url_buscada': query if query_type == 'url' else None,\n",
        "        'url_encontrada': url_final,\n",
        "        'dominio': dominio,\n",
        "        'razon_social': razon_social,\n",
        "        'taxID': tax_id,\n",
        "        'brand': brand,\n",
        "        'email': email,\n",
        "        'telefono': telefono,\n",
        "        'direccion': direccion,\n",
        "        'productos_servicios': productos_servicios,\n",
        "        'titulo': titulo,\n",
        "        'descripcion': descripcion,\n",
        "        'palabras_clave': palabras_clave,\n",
        "        'encabezados': encabezados,\n",
        "        'enlaces': enlaces,\n",
        "        'parrafos': parrafos,\n",
        "        'imagenes': imagenes,\n",
        "        'tablas': tablas\n",
        "    }\n",
        "\n",
        "# --- Nuevo listado de empresas con URLs y/o nombres ---\n",
        "listado_empresas = [\n",
        "    {\"nombre\": \"ENERCA S.A. E.S.P.\"}, # Solo nombre\n",
        "    {\"url\": \"https://www.anla.gov.co/\"}, # Solo URL\n",
        "    {\"nombre\": \"JURISDICCIÓN ESPECIAL PARA LA PAZ (JEP)\", \"url\": \"https://www.jep.gov.co/JEP/Paginas/Jurisdiccion-Especial-para-la-Paz.aspx\"}, # Ambos\n",
        "    {\"url\": \"https://www.esap.edu.co/?ref=elfrente.com.co\"},\n",
        "    {\"nombre\": \"INSTITUTO NACIONAL DE VIGILANCIA DE MEDICAMENTOS Y ALIMENTOS (INVIMA)\"},\n",
        "    {\"url\": \"https://www.fng.gov.co/\"},\n",
        "    {\"nombre\": \"CORPORACIÓN AUTÓNOMA REGIONAL RIONEGRO-NARE (CORNARE)\", \"url\": \"https://www.cornare.gov.co/\"},\n",
        "    {\"url\": \"https://www.tumaco-narino.gov.co/\"},\n",
        "    {\"nombre\": \"LIGA COLOMBIANA CONTRA EL CÁNCER\"},\n",
        "    {\"url\": \"https://www.inci.gov.co/\"},\n",
        "    {\"nombre\": \"INSTITUTO COLOMBIANO AGROPECUARIO (ICA)\"},\n",
        "    {\"url\": \"https://www.balboa-risaralda.gov.co/\"},\n",
        "    {\"nombre\": \"GOBERNACIÓN DEL VALLE DEL CAUCA\"}, # Solo nombre\n",
        "    {\"url\": \"http://lamerced-caldas.gov.co/\"},\n",
        "    {\"nombre\": \"AGENCIA PARA LA REINCORPORACIÓN Y LA NORMALIZACIÓN\", \"url\": \"https://www.reincorporacion.gov.co/es\"},\n",
        "    {\"url\": \"http://esecentrodesaludzetaquira.gov.co/\"},\n",
        "    {\"nombre\": \"INSTITUTO GEOGRÁFICO AGUSTÍN CODAZZI (IGAC)\"},\n",
        "    {\"nombre\": \"SENADO DE LA REPÚBLICA DE COLOMBIA\"},\n",
        "    {\"url\": \"https://www.volcan.com.pe/en/\"},\n",
        "    {\"url\": \"https://ecuaquimica.com.ec/\"},\n",
        "    {\"url\": \"https://www.adelca.com/\"},\n",
        "    {\"url\": \"https://gocorp.com/\"},\n",
        "    {\"url\": \"https://www.sancarlos.com.ec/\"},\n",
        "    {\"url\": \"https://www.facebook.com/eljuridivisionlicores/\"},\n",
        "    {\"url\": \"https://www.cajaarequipa.pe/\"},\n",
        "    {\"url\": \"https://www.ajegroup.com/\"},\n",
        "    {\"url\": \"https://www.exalmar.com.pe/en/\"},\n",
        "    {\"url\": \"https://www.tstt.co.tt/\"},\n",
        "    {\"url\": \"https://www.bancoagricola.com/\"},\n",
        "    {\"url\": \"https://www.cafebritt.com/?srsltid=AfmBOopz--QU1VspyVC7tUUg5S_v1aDH86rJpME5PzNZxRR8AR17sxm6\"},\n",
        "    {\"url\": \"https://www.banrural.com.gt/site/conocenos/grupofinancierobanrural\"},\n",
        "    {\"url\": \"https://my.clevelandclinic.org/health/diseases/17032-glioblastoma\"},\n",
        "    {\"url\": \"https://eng.disagro.com/\"},\n",
        "    {\"url\": \"https://www.bancocuscatlan.com/persona\"},\n",
        "    {\"url\": \"https://www.bam.org/\"},\n",
        "    {\"url\": \"https://agrokasa.com/en/\"},\n",
        "    {\"url\": \"https://www.copaair.com/\"},\n",
        "    {\"url\": \"https://bhd.com.do/\"},\n",
        "    {\"url\": \"https://motorcredito.com.do/\"},\n",
        "    {\"url\": \"https://refidomsa.com/\"},\n",
        "    {\"url\": \"https://cibao.com.do/banca-personal\"},\n",
        "    {\"url\": \"https://www.bcie.org/\"},\n",
        "    {\"url\": \"https://www.tigo.com.hn/\"},\n",
        "    {\"url\": \"https://www.millicom.com/\"},\n",
        "    {\"url\": \"https://www.banesco.com.pa/\"},\n",
        "    {\"url\": \"https://www.libertypr.com/en/\"},\n",
        "    {\"url\": \"https://www.digitel.com.ve/la-corporacion\"}\n",
        "]\n",
        "\n",
        "# Realizar el scraping para cada entrada del listado\n",
        "resultados_empresas = []\n",
        "for item in listado_empresas:\n",
        "    if \"url\" in item and item[\"url\"]:\n",
        "        # Si tiene URL, la procesa directamente\n",
        "        resultado = scraping_data(item[\"url\"], \"url\")\n",
        "    elif \"nombre\" in item and item[\"nombre\"]:\n",
        "        # Si solo tiene nombre, lo busca en Google\n",
        "        resultado = scraping_data(item[\"nombre\"], \"nombre\")\n",
        "    else:\n",
        "        logging.warning(\"Entrada de lista vacía, saltando...\")\n",
        "        continue\n",
        "\n",
        "    if resultado:\n",
        "        resultados_empresas.append(resultado)\n",
        "\n",
        "    # Retardo aleatorio para evitar bloqueos\n",
        "    time.sleep(random.uniform(5, 10))\n",
        "\n",
        "# Guardar los resultados en un DataFrame de pandas y un archivo Excel\n",
        "df_resultados = pd.DataFrame(resultados_empresas)\n",
        "df_resultados.to_excel(\"/content/resultados_y_o_mejorado.xlsx\", index=False)\n",
        "\n",
        "print(\"Resultados guardados en /content/resultados_y_o_mejorado.xlsx\")"
      ],
      "metadata": {
        "id": "j7jbTDiBeFbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from googlesearch import search\n",
        "from urllib.parse import urlparse\n",
        "import time\n",
        "import logging\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Deshabilita las advertencias de certificados no verificados\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "# Configuración del logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Lista de User-Agents para rotar\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/89.0',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.59 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'\n",
        "]\n",
        "\n",
        "def scraping_data(query, query_type):\n",
        "    \"\"\"\n",
        "    Función unificada para realizar web scraping, ya sea por URL o por nombre.\n",
        "    \"\"\"\n",
        "    # Selecciona un User-Agent al azar para cada solicitud\n",
        "    headers = {'User-Agent': random.choice(user_agents)}\n",
        "    url_final = None\n",
        "\n",
        "    if query_type == \"url\":\n",
        "        url_final = query\n",
        "    elif query_type == \"nombre\":\n",
        "        try:\n",
        "            resultados_busqueda = list(search(query, stop=1, pause=random.uniform(2, 4)))\n",
        "            if not resultados_busqueda:\n",
        "                logging.warning(f\"No se encontró URL para el nombre: {query}\")\n",
        "                return None\n",
        "            url_final = resultados_busqueda[0]\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error en la búsqueda de Google para '{query}': {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        logging.error(\"Tipo de consulta no válido. Use 'url' o 'nombre'.\")\n",
        "        return None\n",
        "\n",
        "    logging.info(f\"URL final a procesar: {url_final}\")\n",
        "\n",
        "    dominio = urlparse(url_final).netloc\n",
        "\n",
        "    response = None\n",
        "    for _ in range(3):\n",
        "        try:\n",
        "            response = requests.get(url_final, headers=headers, timeout=30, verify=False)\n",
        "            response.raise_for_status()\n",
        "            break\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logging.error(f\"Intento fallido para {url_final}: {e}. Reintentando...\")\n",
        "            time.sleep(random.uniform(5, 10))\n",
        "\n",
        "    if not response:\n",
        "        logging.error(f\"No se pudo acceder a la URL después de varios intentos: {url_final}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    titulo = soup.title.text.strip() if soup.title else None\n",
        "    descripcion = soup.find('meta', {'name': 'description'})\n",
        "    descripcion = descripcion['content'].strip() if descripcion else None\n",
        "    palabras_clave = soup.find('meta', {'name': 'keywords'})\n",
        "    palabras_clave = palabras_clave['content'].strip() if palabras_clave else None\n",
        "    encabezados = [h.text.strip() for h in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n",
        "    enlaces = [link.get('href') for link in soup.find_all('a', href=True)]\n",
        "    parrafos = [p.text.strip() for p in soup.find_all('p')]\n",
        "    imagenes = [img.get('src') for img in soup.find_all('img', src=True)]\n",
        "    tablas = []\n",
        "    for table in soup.find_all('table'):\n",
        "        table_data = []\n",
        "        for row in table.find_all('tr'):\n",
        "            row_data = [cell.text.strip() for cell in row.find_all(['td', 'th'])]\n",
        "            table_data.append(row_data)\n",
        "        tablas.append(table_data)\n",
        "\n",
        "    razon_social = None\n",
        "    tax_id = None\n",
        "    brand = None\n",
        "    email = None\n",
        "    telefono = None\n",
        "    direccion = None\n",
        "    productos_servicios = []\n",
        "\n",
        "    for script in soup.find_all('script', type='application/ld+json'):\n",
        "        if script.string:\n",
        "            try:\n",
        "                data = json.loads(script.string)\n",
        "                if isinstance(data, list):\n",
        "                    for item in data:\n",
        "                        if item.get('@type') in ['Organization', 'LocalBusiness']:\n",
        "                            razon_social = item.get('name')\n",
        "                            tax_id = item.get('taxID')\n",
        "                            brand = item.get('brand')\n",
        "                            if item.get('address') and isinstance(item['address'], dict):\n",
        "                                direccion = item['address'].get('streetAddress')\n",
        "                            if item.get('contactPoint') and isinstance(item['contactPoint'], list):\n",
        "                                for cp in item['contactPoint']:\n",
        "                                    if cp.get('contactType') == 'customer service' or cp.get('contactType') == 'general':\n",
        "                                        telefono = cp.get('telephone')\n",
        "                                        email = cp.get('email')\n",
        "                        elif item.get('@type') in ['Product', 'Service']:\n",
        "                            productos_servicios.append(item.get('name'))\n",
        "                elif data.get('@type') in ['Organization', 'LocalBusiness']:\n",
        "                    razon_social = data.get('name')\n",
        "                    tax_id = data.get('taxID')\n",
        "                    brand = data.get('brand')\n",
        "                    if data.get('address') and isinstance(data['address'], dict):\n",
        "                        direccion = data['address'].get('streetAddress')\n",
        "                    if data.get('contactPoint') and isinstance(data['contactPoint'], list):\n",
        "                        for cp in data['contactPoint']:\n",
        "                            if cp.get('contactType') == 'customer service' or cp.get('contactType') == 'general':\n",
        "                                telefono = cp.get('telephone')\n",
        "                                email = cp.get('email')\n",
        "                elif data.get('@type') in ['Product', 'Service']:\n",
        "                    productos_servicios.append(data.get('name'))\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "    if not razon_social:\n",
        "        razon_social_element = soup.find('h1')\n",
        "        razon_social = razon_social_element.text.strip() if razon_social_element else None\n",
        "\n",
        "    if not email:\n",
        "        email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.[\\w\\.]+', str(soup))\n",
        "        email = email_match.group(0) if email_match else None\n",
        "\n",
        "    if not telefono:\n",
        "        telefono_match = re.search(r'(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', str(soup))\n",
        "        telefono = telefono_match.group(0) if telefono_match else None\n",
        "\n",
        "    return {\n",
        "        'nombre_buscado': query if query_type == 'nombre' else None,\n",
        "        'url_buscada': query if query_type == 'url' else None,\n",
        "        'url_encontrada': url_final,\n",
        "        'dominio': dominio,\n",
        "        'razon_social': razon_social,\n",
        "        'taxID': tax_id,\n",
        "        'brand': brand,\n",
        "        'email': email,\n",
        "        'telefono': telefono,\n",
        "        'direccion': direccion,\n",
        "        'productos_servicios': productos_servicios,\n",
        "        'titulo': titulo,\n",
        "        'descripcion': descripcion,\n",
        "        'palabras_clave': palabras_clave,\n",
        "        'encabezados': encabezados,\n",
        "        'enlaces': enlaces,\n",
        "        'parrafos': parrafos,\n",
        "        'imagenes': imagenes,\n",
        "        'tablas': tablas\n",
        "    }\n",
        "\n",
        "# --- Nuevo listado de empresas con URLs y nombres ---\n",
        "# Hemos estructurado la lista para que cada elemento sea un diccionario\n",
        "# con una URL y un nombre, o solo uno de ellos.\n",
        "listado_empresas = [\n",
        "    {\"url\": \"enerca.com.co\", \"nombre\": \"ENERCA S.A. E.S.P.\"},\n",
        "    {\"url\": \"anla.gov.co\", \"nombre\": \"AUTORIDAD NACIONAL DE LICENCIAS AMBIENTALES (ANLA)\"},\n",
        "    {\"url\": \"jep.gov.co\", \"nombre\": \"JURISDICCIÓN ESPECIAL PARA LA PAZ (JEP)\"},\n",
        "    {\"url\": \"esap.edu.co\", \"nombre\": \"ESCUELA SUPERIOR DE ADMINISTRACIÓN PÚBLICA (ESAP)\"},\n",
        "    {\"url\": \"invima.gov.co\", \"nombre\": \"INSTITUTO NACIONAL DE VIGILANCIA DE MEDICAMENTOS Y ALIMENTOS (INVIMA)\"},\n",
        "    {\"url\": \"fiduprevisora.com.co\", \"nombre\": \"FIDUPREVISORA S.A.\"},\n",
        "    {\"url\": \"cali.gov.co\", \"nombre\": \"ALCALDÍA DE SANTIAGO DE CALI\"},\n",
        "    {\"url\": \"fng.gov.co\", \"nombre\": \"FONDO NACIONAL DE GARANTÍAS\"},\n",
        "    {\"url\": \"cornare.gov.co\", \"nombre\": \"CORPORACIÓN AUTÓNOMA REGIONAL RIONEGRO-NARE (CORNARE)\"},\n",
        "    {\"url\": \"tumaco-narino.gov.co\", \"nombre\": \"ALCALDÍA DE TUMACO, NARIÑO\"},\n",
        "    {\"url\": \"cancer.gov.co\", \"nombre\": \"LIGA COLOMBIANA CONTRA EL CÁNCER\"},\n",
        "    {\"url\": \"inci.gov.co\", \"nombre\": \"INSTITUTO NACIONAL PARA CIEGOS (INCI)\"},\n",
        "    {\"url\": \"ica.gov.co\", \"nombre\": \"INSTITUTO COLOMBIANO AGROPECUARIO (ICA)\"},\n",
        "    {\"url\": \"balboa-risaralda.gov.co\", \"nombre\": \"ALCALDÍA DE BALBOA, RISARALDA\"},\n",
        "    {\"url\": \"valledelcauca.gov.co\", \"nombre\": \"GOBERNACIÓN DEL VALLE DEL CAUCA\"},\n",
        "    {\"url\": \"fng.gov.co\", \"nombre\": \"FONDO NACIONAL DE GARANTÍAS\"},\n",
        "    {\"url\": \"invima.gov.co\", \"nombre\": \"INSTITUTO NACIONAL DE VIGILANCIA DE MEDICAMENTOS Y ALIMENTOS (INVIMA)\"},\n",
        "    {\"url\": \"lamerced-caldas.gov.co\", \"nombre\": \"ALCALDÍA DE LA MERCED, CALDAS\"},\n",
        "    {\"url\": \"elretiro-antioquia.gov.co\", \"nombre\": \"ALCALDÍA DE EL RETIRO, ANTIOQUIA\"},\n",
        "    {\"url\": \"reincorporacion.gov.co\", \"nombre\": \"AGENCIA PARA LA REINCORPORACIÓN Y LA NORMALIZACIÓN\"},\n",
        "    {\"url\": \"mindefensa.gov.co\", \"nombre\": \"MINISTERIO DE DEFENSA NACIONAL\"},\n",
        "    {\"url\": \"esecentrodesaludzetaquira.gov.co\", \"nombre\": \"ESE CENTRO DE SALUD DE ZETAQUIRA\"},\n",
        "    {\"url\": \"igac.gov.co\", \"nombre\": \"INSTITUTO GEOGRÁFICO AGUSTÍN CODAZZI (IGAC)\"},\n",
        "    {\"url\": \"fiduprevisora.com.co\", \"nombre\": \"FIDUPREVISORA S.A.\"},\n",
        "    {\"url\": \"fiduprevisora.com.co\", \"nombre\": \"FIDUPREVISORA S.A.\"},\n",
        "    {\"url\": \"igac.gov.co\", \"nombre\": \"INSTITUTO GEOGRÁFICO AGUSTÍN CODAZZI (IGAC)\"},\n",
        "    {\"url\": \"senado.gov.co\", \"nombre\": \"SENADO DE LA REPÚBLICA DE COLOMBIA\"},\n",
        "    {\"url\": \"pereira.gov.co\", \"nombre\": \"ALCALDÍA DE PEREIRA\"},\n",
        "    {\"url\": \"igac.gov.co\", \"nombre\": \"INSTITUTO GEOGRÁFICO AGUSTÍN CODAZZI (IGAC)\"},\n",
        "    {\"url\": \"fng.gov.co\", \"nombre\": \"FONDO NACIONAL DE GARANTÍAS\"},\n",
        "    {\"url\": \"clinicainternacional.com.pe\", \"nombre\": \"Clínica Internacional\"},\n",
        "    {\"url\": \"lima-airport.com\", \"nombre\": \"LIMA AIRPORT\"},\n",
        "    {\"url\": \"antamina.com\", \"nombre\": \"Antamina\"},\n",
        "    {\"url\": \"volcan.com.pe\", \"nombre\": \"Volcan Compañía Minera\"},\n",
        "    {\"url\": \"bancoguayaquil.com\", \"nombre\": \"Banco Guayaquil\"},\n",
        "    {\"url\": \"ecuaquimica.com\", \"nombre\": \"Ecuaquimica\"},\n",
        "    {\"url\": \"adelca.com\", \"nombre\": \"Adelca\"},\n",
        "    {\"url\": \"gerardoortiz.com\", \"nombre\": \"GO CORP\"},\n",
        "    {\"url\": \"danec.com\", \"nombre\": \"Danec S.A.\"},\n",
        "    {\"url\": \"sancarlos.com.ec\", \"nombre\": \"Sociedad Agrícola e Industrial San Carlos S.A.\"},\n",
        "    {\"url\": \"cargill.com\", \"nombre\": \"Cargill\"},\n",
        "    {\"url\": \"grupoeljuri.com\", \"nombre\": \"Eljuri Licores\"},\n",
        "    {\"url\": \"cajaarequipa.pe\", \"nombre\": \"Caja Arequipa\"},\n",
        "    {\"url\": \"ajegroup.com\", \"nombre\": \"Grupo AJE\"},\n",
        "    {\"url\": \"latina.pe\", \"nombre\": \"Latina\"},\n",
        "    {\"url\": \"exalmar.com.pe\", \"nombre\": \"Pesquera Exalmar SAA\"},\n",
        "    {\"url\": \"edeeste.com.do\", \"nombre\": \"Edeeste\"},\n",
        "    {\"url\": \"tstt.co.tt\", \"nombre\": \"Telecommunications Services of Trinidad & Tobago Limited (TSTT)\"},\n",
        "    {\"url\": \"bancoagricola.com\", \"nombre\": \"Bancoagrícola\"},\n",
        "    {\"url\": \"cafebritt.com\", \"nombre\": \"Café Britt\"},\n",
        "    {\"url\": \"ccn.com.ni\", \"nombre\": \"Compañia Cervecera de Nicaragua S.A\"},\n",
        "    {\"url\": \"laprensagrafica.com\", \"nombre\": \"La Prensa Grafica\"},\n",
        "    {\"url\": \"banrural.com.gt\", \"nombre\": \"Grupo Financiero Banrural\"},\n",
        "    {\"url\": \"gbm.net\", \"nombre\": \"GBM\"},\n",
        "    {\"url\": \"bantrab.com.gt\", \"nombre\": \"Bantrab\"},\n",
        "    {\"url\": \"disagro.com\", \"nombre\": \"DISAGRO\"},\n",
        "    {\"url\": \"bancocuscatlan.com\", \"nombre\": \"Banco Cuscatlán El Salvador\"},\n",
        "    {\"url\": \"bam.com.gt\", \"nombre\": \"Bam\"},\n",
        "    {\"url\": \"agrokasa.com\", \"nombre\": \"Sociedad Agrícola Drokasa S.A.\"},\n",
        "    {\"url\": \"cbc.co\", \"nombre\": \"cbc\"},\n",
        "    {\"url\": \"copaair.com\", \"nombre\": \"Copa Airlines\"},\n",
        "    {\"url\": \"butterfieldgroup.com\", \"nombre\": \"Butterfield Group\"},\n",
        "    {\"url\": \"tigo.com.co\", \"nombre\": \"Tigo Colombia\"},\n",
        "    {\"url\": \"bhd.com.do\", \"nombre\": \"Banco BHD\"},\n",
        "    {\"url\": \"motorcredito.com.do\", \"nombre\": \"Motor Crédito, S. A., Banco de Ahorro & Crédito\"},\n",
        "    {\"url\": \"refidomsa.com.do\", \"nombre\": \"Refidomsa PDV, S.A.\"},\n",
        "    {\"url\": \"acap.com.do\", \"nombre\": \"Asociación Cibao de Ahorros y Préstamos\"},\n",
        "    {\"url\": \"bcie.org\", \"nombre\": \"Banco Centroamericano de Integración Económica - BCIE\"},\n",
        "    {\"url\": \"tigo.com.hn\", \"nombre\": \"Tigo Honduras.\"},\n",
        "    {\"url\": \"millicom.com\", \"nombre\": \"Millicom (Tigo)\"},\n",
        "    {\"url\": \"bancocaribe.com.do\", \"nombre\": \"BANCO CARIBE\"},\n",
        "    {\"url\": \"banesco.com.pa\", \"nombre\": \"Banesco Panamá\"},\n",
        "    {\"url\": \"canalbank.com\", \"nombre\": \"Canalbank\"},\n",
        "    {\"url\": \"libertypr.com\", \"nombre\": \"Liberty of Puerto Rico\"},\n",
        "    {\"url\": \"digitel.com.ve\", \"nombre\": \"Corporación Digitel\"}\n",
        "]\n",
        "\n",
        "# Realizar el scraping para cada entrada del listado\n",
        "resultados_empresas = []\n",
        "for item in listado_empresas:\n",
        "    url_found = False\n",
        "\n",
        "    # Intenta con la URL primero\n",
        "    if \"url\" in item and item[\"url\"]:\n",
        "        # Se añade un protocolo si falta para evitar errores de requests\n",
        "        full_url = item[\"url\"]\n",
        "        if not full_url.startswith('http://') and not full_url.startswith('https://'):\n",
        "            full_url = 'https://' + full_url\n",
        "\n",
        "        resultado = scraping_data(full_url, \"url\")\n",
        "        if resultado and resultado['dominio']:\n",
        "            # Si se obtiene un resultado válido de la URL, lo usa\n",
        "            resultados_empresas.append(resultado)\n",
        "            url_found = True\n",
        "        else:\n",
        "            logging.warning(f\"La URL {full_url} falló. Intentando con el nombre.\")\n",
        "\n",
        "    # Si la URL falla o no está disponible, intenta con el nombre\n",
        "    if not url_found and \"nombre\" in item and item[\"nombre\"]:\n",
        "        resultado = scraping_data(item[\"nombre\"], \"nombre\")\n",
        "        if resultado:\n",
        "            resultados_empresas.append(resultado)\n",
        "\n",
        "    # Retardo aleatorio para evitar bloqueos\n",
        "    time.sleep(random.uniform(5, 10))\n",
        "\n",
        "# Guardar los resultados en un DataFrame de pandas y un archivo Excel\n",
        "df_resultados = pd.DataFrame(resultados_empresas)\n",
        "df_resultados.to_excel(\"/content/resultados_completo.xlsx\", index=False)\n",
        "\n",
        "print(\"Resultados guardados en /content/resultados_completo.xlsx\")"
      ],
      "metadata": {
        "id": "C3z5A8dChLBL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}